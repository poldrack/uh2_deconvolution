{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summarize deconvolution results\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "\n",
    "basedir = '/Users/poldrack/data_unsynced/uh2/BIDS_data/derivatives/deconvolution'\n",
    "figure_dir = os.path.join(basedir, 'figures')\n",
    "if not os.path.exists(figure_dir):\n",
    "    os.mkdir(figure_dir)\n",
    "resultfiles = glob(os.path.join(basedir, 'sub*/func/*_deconvolved.tsv'))\n",
    "templateflow_home  = os.environ['TEMPLATEFLOW_HOME']\n",
    "\n",
    "\n",
    "# set the intended values to match on here\n",
    "spec_dict = {'use_ridge': False,\n",
    "            'atlas': 'Schaefer2018',\n",
    "            'use_confounds': True,\n",
    "            'desc': '400Parcels17Networks',\n",
    "            }\n",
    "\n",
    "def spec_dict_to_string(spec_dict):\n",
    "    spec_string = []\n",
    "    for k in spec_dict:\n",
    "        spec_string.append('%s-%s' % (k, spec_dict[k]))\n",
    "    return('_'.join(spec_string))\n",
    "\n",
    "\n",
    "spec_string = spec_dict_to_string(spec_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deconv_file_info_from_json(filename):\n",
    "    with open(filename.replace('.tsv', '.json')) as f:\n",
    "        info_dict = json.load(f)\n",
    "    info_dict ['filename'] = filename\n",
    "    full_split = info_dict['filename'].split('/')\n",
    "    info_dict['basedir'] = '/'.join(full_split[:-6])\n",
    "    info_dict['deriv_base'] = '/'.join(full_split[:-5])\n",
    "    info_dict['desc'] = info_dict['atlas_desc']\n",
    "    return(info_dict)\n",
    "\n",
    "\n",
    "def check_spec_match(info_dict, spec_dict):\n",
    "    spec_match = True\n",
    "    for key in spec_dict:\n",
    "        if info_dict[key] != spec_dict[key]:\n",
    "            #print('mismatch:', info_dict[key], spec_dict[key])\n",
    "            spec_match = False\n",
    "    return(spec_match)\n",
    "\n",
    "\n",
    "datafiles = collections.defaultdict(lambda :[])\n",
    "info_dict = {}\n",
    "for filename in resultfiles:\n",
    "    idict = get_deconv_file_info_from_json(filename)\n",
    "    if check_spec_match(idict, spec_dict):\n",
    "        info_dict[filename] = idict\n",
    "        datafiles[info_dict[filename]['task']].append(filename)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_deconv_data(df):\n",
    "    # the data from nideconv have multiple rows with identical values\n",
    "    # which we drop to save time later on\n",
    "    data_df = df.copy()\n",
    "    # since time varies, we need to set it to the index so it won't be counted\n",
    "    data_df.index = data_df.time\n",
    "    del data_df['time']\n",
    "    data_df = data_df.drop_duplicates()\n",
    "    return(data_df)\n",
    "\n",
    "def get_atlas_info(spec_dict, templateflow_home):\n",
    "    atlas_info_file = os.path.join(\n",
    "        templateflow_home,\n",
    "        f'tpl-MNI152NLin2009cAsym/tpl-MNI152NLin2009cAsym_atlas-{spec_dict[\"atlas\"]}_desc-{spec_dict[\"desc\"]}_dseg.tsv')\n",
    "    atlas_info = pd.read_csv(atlas_info_file, sep='\\t')\n",
    "    atlas_info['network'] = [i.split('_')[2] for i in atlas_info.name]\n",
    "    return(atlas_info)\n",
    "\n",
    "def summarize_by_yeo_network(df, spec_dict):\n",
    "    status_vars = ('event type', 'covariate', 'time', 'subcode')\n",
    "    data_df = df.copy()\n",
    "    for v in status_vars:\n",
    "        if v in data_df:\n",
    "            del data_df[v]\n",
    "\n",
    "    atlas_info = get_atlas_info(spec_dict, os.environ['TEMPLATEFLOW_HOME'])\n",
    "    \n",
    "    networks = atlas_info.network.unique()\n",
    "    networks_df = pd.DataFrame(index = data_df.index)\n",
    "    for network in networks:\n",
    "        network_idx = atlas_info.network == network\n",
    "        networks_df.loc[:, network] = np.mean(data_df.values[:, network_idx], 1)\n",
    "    networks_df.columns = networks\n",
    "    for v in status_vars:\n",
    "        if v in df.columns and v != 'covariate':\n",
    "            networks_df.loc[:, v.replace(' ', '_')] = df.loc[:, v]\n",
    "    return(networks_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_timeseries(df, smoothing_window = 5):\n",
    "    status_vars = ('time', 'event_type')\n",
    "    data_df = df.copy()\n",
    "    smoothed_data = None\n",
    "    \n",
    "    # smooth separately for each event type since they\n",
    "    # are concatenated in the dataset\n",
    "    for event_type in data_df.event_type.unique():\n",
    "        event_data = data_df.query('event_type == \"%s\"' % event_type)\n",
    "        for c in event_data.columns:\n",
    "            if c in status_vars:\n",
    "                continue\n",
    "            event_data.loc[:, c] = event_data.loc[:, c].rolling(smoothing_window).mean()\n",
    "            if smoothed_data is None:\n",
    "                smoothed_data = event_data\n",
    "            else:\n",
    "                smoothed_data = pd.concat((smoothed_data, event_data))\n",
    "\n",
    "    return(smoothed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 97 datasets for task discountFix\n",
      "found 100 datasets for task stroop\n",
      "found 100 datasets for task DPX\n",
      "found 101 datasets for task ANT\n",
      "found 104 datasets for task WATT3\n",
      "found 104 datasets for task twoByTwo\n",
      "found 103 datasets for task stopSignal\n",
      "found 102 datasets for task CCTHot\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_combined_data(datafiles, info_dict, spec_dict):\n",
    "    combined_data = None\n",
    "    for task in datafiles:\n",
    "        print(f'found {len(datafiles[task])} datasets for task {task}')\n",
    "        for datafile in datafiles[task]:\n",
    "            data = pd.read_csv(datafile, sep='\\t')\n",
    "            data_simple = simplify_deconv_data(data)\n",
    "            yeo_data = summarize_by_yeo_network(data_simple, spec_dict)\n",
    "            yeo_data_smooth = smooth_timeseries(yeo_data)\n",
    "            yeo_data_smooth['subcode'] = info_dict[datafile]['sub']\n",
    "            yeo_data_smooth['task'] = task\n",
    "            yeo_data_smooth['time'] = yeo_data.index\n",
    "            if combined_data is None:\n",
    "                combined_data = yeo_data_smooth\n",
    "            else:\n",
    "                combined_data = pd.concat((combined_data, yeo_data_smooth))\n",
    "\n",
    "    combined_data_long = pd.melt(combined_data,\n",
    "                                 id_vars=['event_type', 'subcode', 'task', 'time'],\n",
    "                                 var_name='network', value_name='response')\n",
    "    return(combined_data_long)\n",
    "\n",
    "from create_deconv_images import get_combined_data\n",
    "\n",
    "combined_data_long = get_combined_data(datafiles, info_dict, spec_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_network_plots(combined_data, task, spec_string, figure_dir):\n",
    "    df = combined_data_long.query('task == \"%s\"' % task)\n",
    "    p = sns.relplot(x='time', y='response', col=\"network\", \n",
    "                    col_wrap=4, height=4, hue='event_type', \n",
    "                    data=df, kind='line')\n",
    "    p.add_legend()\n",
    "    p.fig.suptitle(task, fontsize=16)\n",
    "    p.map(plt.axhline, y=0, ls='--', c='gray')\n",
    "    #plt.savefig(os.path.join(figure_dir, '%s_%s_deconv.pdf' % (task, spec_string)))\n",
    "    \n",
    "for task in combined_data.task.unique():\n",
    "    print('plotting', task)\n",
    "    make_network_plots(combined_data, task, spec_string, figure_dir)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'CCTHot'\n",
    "df = combined_data_long.query('task == \"%s\"' % task)\n",
    "p = sns.relplot(x='time', y='response', col=\"network\", col_wrap=4, height=4, hue='event_type', data=df, kind='line')\n",
    "p.add_legend()\n",
    "p.map(plt.axhline, y=0, ls='--', c='gray')\n",
    "p.fig.suptitle(task, fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ri = combined_data.copy()\n",
    "if 'time' in ri:\n",
    "    del ri['time']\n",
    "ri = ri.reindex()\n",
    "mean_resp = ri.groupby(['task', 'event_type', 'time']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
